{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ff2900-c744-44c9-a4af-7f9f2b8d9c7e",
   "metadata": {},
   "source": [
    "## Initialize SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "975b1b30-85ac-4a6f-8709-9890e40e286c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/19 02:30:40 WARN Utils: Your hostname, Kavanas-MacBook-Air.local, resolves to a loopback address: 127.0.0.1; using 10.0.0.58 instead (on interface en0)\n",
      "25/11/19 02:30:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/19 02:30:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/11/19 02:30:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/11/19 02:30:44 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/11/19 02:30:44 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ProductDailyMetrics\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4edf4b-833d-45ac-a2e6-d66f87840abb",
   "metadata": {},
   "source": [
    "### Load Silver clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e06b17a-237e-4a59-9e12-b5708858a361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------+-------------+--------------------+\n",
      "|             user_id|      asin|rating|    timestamp|          event_time|\n",
      "+--------------------+----------+------+-------------+--------------------+\n",
      "|AG7FJJNE73SLYFJAY...|B072HX2DV8|   2.0|1509154387973|+49793-03-13 11:1...|\n",
      "|AG7FJJNE73SLYFJAY...|B002I0JB6E|   1.0|1324856968000|+43953-01-17 10:2...|\n",
      "|AELASOADJU4SUNNTF...|B084DDDNRP|   5.0|1613751527651|+53107-10-02 12:1...|\n",
      "|AELASOADJU4SUNNTF...|B07GTT1Q92|   5.0|1555365983227|+51257-08-01 21:2...|\n",
      "|AHIWJKGSBL5XAQKKS...|B07CZZC3GP|   5.0|1551407187448|+51132-02-20 10:5...|\n",
      "+--------------------+----------+------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- asin: string (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- event_time: timestamp (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "\n",
    "silver_path = \"/Users/kavanamanvi/Desktop/AmazonReviews/processed/silver/reviews_clean\"\n",
    "df = spark.read.parquet(silver_path)\n",
    "\n",
    "df.show(5)\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c067bbb-5fc5-4c29-877e-c2b3c551692a",
   "metadata": {},
   "source": [
    "### Add a date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d3f9559-349d-4e82-8232-8dd4e4eb95d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------+-------------+--------------------+------------+\n",
      "|             user_id|      asin|rating|    timestamp|          event_time|        date|\n",
      "+--------------------+----------+------+-------------+--------------------+------------+\n",
      "|AG7FJJNE73SLYFJAY...|B072HX2DV8|   2.0|1509154387973|+49793-03-13 11:1...|+49793-03-13|\n",
      "|AG7FJJNE73SLYFJAY...|B002I0JB6E|   1.0|1324856968000|+43953-01-17 10:2...|+43953-01-17|\n",
      "|AELASOADJU4SUNNTF...|B084DDDNRP|   5.0|1613751527651|+53107-10-02 12:1...|+53107-10-02|\n",
      "|AELASOADJU4SUNNTF...|B07GTT1Q92|   5.0|1555365983227|+51257-08-01 21:2...|+51257-08-01|\n",
      "|AHIWJKGSBL5XAQKKS...|B07CZZC3GP|   5.0|1551407187448|+51132-02-20 10:5...|+51132-02-20|\n",
      "+--------------------+----------+------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "df_with_date = df.withColumn(\"date\", to_date(\"event_time\"))\n",
    "df_with_date.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff23079c-5376-4a03-a323-066c7972d512",
   "metadata": {},
   "source": [
    "## Prepare Aggregations\n",
    "\n",
    "We need metrics per product per day.\n",
    "\n",
    "### Metrics:\n",
    "\n",
    "avg rating\n",
    "\n",
    "review count\n",
    "\n",
    "verified count (if present)\n",
    "\n",
    "helpful vote sum (if present)\n",
    "\n",
    "rating distribution\n",
    "\n",
    "min/max\n",
    "\n",
    "earliest/latest review date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecd4e921-710a-4866-b64a-3a7fab379280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions needed for aggregation\n",
    "from pyspark.sql.functions import (\n",
    "    avg, count, sum as spark_sum, min, max,\n",
    "    countDistinct, expr, first, last\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1122ae5-f6db-49fc-838d-8ebc465b0f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by asin, date and compute aggregates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38e4aee9-a77d-4ade-8b2b-abee3b9dcb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "daily_metrics = df_with_date.groupBy(\"asin\", \"date\").agg(\n",
    "    F.avg(\"rating\").alias(\"avg_rating\"),\n",
    "    F.count(\"*\").alias(\"review_count\"),\n",
    "    F.min(\"rating\").alias(\"min_rating\"),\n",
    "    F.max(\"rating\").alias(\"max_rating\"),\n",
    "\n",
    "    F.sum((F.col(\"rating\") == 1).cast(\"int\")).alias(\"rating_1_count\"),\n",
    "    F.sum((F.col(\"rating\") == 2).cast(\"int\")).alias(\"rating_2_count\"),\n",
    "    F.sum((F.col(\"rating\") == 3).cast(\"int\")).alias(\"rating_3_count\"),\n",
    "    F.sum((F.col(\"rating\") == 4).cast(\"int\")).alias(\"rating_4_count\"),\n",
    "    F.sum((F.col(\"rating\") == 5).cast(\"int\")).alias(\"rating_5_count\"),\n",
    "\n",
    "    F.min(\"event_time\").alias(\"first_review_date\"),\n",
    "    F.max(\"event_time\").alias(\"last_review_date\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f59080-724b-48cd-b83b-d4ca9ed59717",
   "metadata": {},
   "source": [
    "## Write the gold dataset partitioned by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c298240-2c15-4898-8af8-5cde387deae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- review_count: long (nullable = false)\n",
      " |-- min_rating: double (nullable = true)\n",
      " |-- max_rating: double (nullable = true)\n",
      " |-- rating_1_count: long (nullable = true)\n",
      " |-- rating_2_count: long (nullable = true)\n",
      " |-- rating_3_count: long (nullable = true)\n",
      " |-- rating_4_count: long (nullable = true)\n",
      " |-- rating_5_count: long (nullable = true)\n",
      " |-- first_review_date: timestamp (nullable = true)\n",
      " |-- last_review_date: timestamp (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+------------+----------+----------+--------------+--------------+--------------+--------------+--------------+--------------------+--------------------+\n",
      "|      asin|        date|avg_rating|review_count|min_rating|max_rating|rating_1_count|rating_2_count|rating_3_count|rating_4_count|rating_5_count|   first_review_date|    last_review_date|\n",
      "+----------+------------+----------+------------+----------+----------+--------------+--------------+--------------+--------------+--------------+--------------------+--------------------+\n",
      "|B000S0C2UI|+44721-04-14|       5.0|           1|       5.0|       5.0|             0|             0|             0|             0|             1|+44721-04-14 06:5...|+44721-04-14 06:5...|\n",
      "|B0BW8N6X48|+55185-06-09|       1.0|           1|       1.0|       1.0|             1|             0|             0|             0|             0|+55185-06-09 09:1...|+55185-06-09 09:1...|\n",
      "|B016K12406|+53753-07-06|       5.0|           1|       5.0|       5.0|             0|             0|             0|             0|             1|+53753-07-06 16:2...|+53753-07-06 16:2...|\n",
      "|B0858X4JQN|+54421-05-02|       5.0|           1|       5.0|       5.0|             0|             0|             0|             0|             1|+54421-05-02 09:0...|+54421-05-02 09:0...|\n",
      "|B0009350BC|+46047-02-18|       3.0|           1|       3.0|       3.0|             0|             0|             1|             0|             0|+46047-02-18 09:5...|+46047-02-18 09:5...|\n",
      "|B003ES5ZVO|+43536-09-18|       5.0|           1|       5.0|       5.0|             0|             0|             0|             0|             1|+43536-09-18 18:0...|+43536-09-18 18:0...|\n",
      "|B07BBCS15Z|+50969-04-24|       5.0|           1|       5.0|       5.0|             0|             0|             0|             0|             1|+50969-04-24 01:3...|+50969-04-24 01:3...|\n",
      "|B00KVSQAGO|+47376-12-29|       5.0|           1|       5.0|       5.0|             0|             0|             0|             0|             1|+47376-12-29 11:3...|+47376-12-29 11:3...|\n",
      "|B00I902D7Q|+47788-06-30|       4.0|           1|       4.0|       4.0|             0|             0|             0|             1|             0|+47788-06-30 06:4...|+47788-06-30 06:4...|\n",
      "|B015WKY3IM|+49057-03-15|       5.0|           1|       5.0|       5.0|             0|             0|             0|             0|             1|+49057-03-15 18:5...|+49057-03-15 18:5...|\n",
      "+----------+------------+----------+------------+----------+----------+--------------+--------------+--------------+--------------+--------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "daily_metrics.printSchema()\n",
    "daily_metrics.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3bbf9ad-29b7-4b31-b8c2-b0202ab09271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.                 (0 + 4) / 4]\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/py4j/clientserver.py\", line 535, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/kavanamanvi/Desktop/AmazonReviews/processed/gold/product_daily_metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m daily_metrics\u001b[38;5;241m.\u001b[39mwrite \\\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mmode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mpartitionBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;241m.\u001b[39mparquet(output_path)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyspark/sql/readwriter.py:2003\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   2001\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[0;32m-> 2003\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39mparquet(path)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/py4j/java_gateway.py:1361\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1356\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1357\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1358\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1359\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1361\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m   1362\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1363\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/py4j/clientserver.py:535\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 535\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    536\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    537\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/socket.py:708\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output_path = \"/Users/kavanamanvi/Desktop/AmazonReviews/processed/gold/product_daily_metrics\"\n",
    "\n",
    "daily_metrics.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"date\") \\\n",
    "    .parquet(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62351902-2ae1-4bcb-9959-12fbab39a1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
